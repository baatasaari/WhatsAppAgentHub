models:
  - id: gpt-4o
    name: OpenAI GPT-4o
    provider: OpenAI
    version: 2024-06
    model_type: transformer
    description: Most capable model for complex conversations
    badge: Recommended
    badge_color: text-green-600
    capabilities:
      - code_generation
      - text_completion
      - reasoning
      - summarization
      - multilingual_support
      - image_input
      - function_calling
    input:
      max_tokens: 128000
      token_encoding: cl100k_base
      formats_supported:
        - text
        - json
        - image
    output:
      response_format: text
      temperature: 0.7
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 500
      burst_latency_ms: 1500
    cost_profile:
      prompt_token_cost_per_1k: 0.005
      completion_token_cost_per_1k: 0.015
      currency: USD
    compliance:
      - GDPR
      - SOC2
      - ISO/IEC 27001
    safety_features:
      - content_filtering
      - PII_redaction
      - prompt_injection_detection
    deployment:
      mode: API
      endpoint: https://api.openai.com/v1/chat/completions
      authentication: Bearer Token
    usage_limits:
      rate_limit_rpm: 3000
      concurrent_requests: 100
    fine_tuning:
      supported: true
      method: instruction tuning
    notes: >-
      GPT-4o supports multi-modal inputs (text + image) and is optimized for
      both latency and cost efficiency in production workloads.
  - id: claude-sonnet-4-20250514
    name: Claude Sonnet 4
    provider: Anthropic
    version: '2025-05-14'
    model_type: transformer
    description: Latest Anthropic model with superior reasoning
    badge: New
    badge_color: text-purple-600
    capabilities:
      - text_completion
      - reasoning
      - analysis
      - creative_writing
      - code_generation
      - multilingual_support
    input:
      max_tokens: 200000
      token_encoding: claude
      formats_supported:
        - text
        - json
    output:
      response_format: text
      temperature: 0.7
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 600
      burst_latency_ms: 1800
    cost_profile:
      prompt_token_cost_per_1k: 0.003
      completion_token_cost_per_1k: 0.015
      currency: USD
    compliance:
      - GDPR
      - SOC2
    safety_features:
      - content_filtering
      - constitutional_AI
      - harmlessness_training
    deployment:
      mode: API
      endpoint: https://api.anthropic.com/v1/messages
      authentication: API Key
    usage_limits:
      rate_limit_rpm: 4000
      concurrent_requests: 50
    fine_tuning:
      supported: false
    notes: >-
      Claude Sonnet 4 is the latest model from Anthropic with enhanced reasoning
      capabilities and constitutional AI safety.
  - id: claude-3-7-sonnet-20250219
    name: Claude 3.7 Sonnet
    provider: Anthropic
    version: '2025-02-19'
    model_type: transformer
    description: Fast and efficient Anthropic model
    badge: Fast
    badge_color: text-blue-600
    capabilities:
      - text_completion
      - reasoning
      - analysis
      - creative_writing
      - code_generation
    input:
      max_tokens: 200000
      token_encoding: claude
      formats_supported:
        - text
        - json
    output:
      response_format: text
      temperature: 0.7
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 400
      burst_latency_ms: 1200
    cost_profile:
      prompt_token_cost_per_1k: 0.003
      completion_token_cost_per_1k: 0.015
      currency: USD
    compliance:
      - GDPR
      - SOC2
    safety_features:
      - content_filtering
      - constitutional_AI
    deployment:
      mode: API
      endpoint: https://api.anthropic.com/v1/messages
      authentication: API Key
    usage_limits:
      rate_limit_rpm: 4000
      concurrent_requests: 50
    fine_tuning:
      supported: false
    notes: Claude 3.7 Sonnet offers excellent performance with faster response times.
  - id: gemini-1.5-pro
    name: Google Gemini 1.5 Pro
    provider: Google
    version: '1.5'
    model_type: multimodal_transformer
    description: Google's advanced multimodal AI
    badge: Multimodal
    badge_color: text-indigo-600
    capabilities:
      - text_completion
      - reasoning
      - code_generation
      - image_analysis
      - video_analysis
      - multimodal_understanding
      - multilingual_support
    input:
      max_tokens: 1000000
      token_encoding: gemini
      formats_supported:
        - text
        - json
        - image
        - video
        - audio
    output:
      response_format: text
      temperature: 0.7
      top_p: 0.9
      max_tokens: 8192
    latency_profile:
      avg_latency_ms: 800
      burst_latency_ms: 2000
    cost_profile:
      prompt_token_cost_per_1k: 0.00125
      completion_token_cost_per_1k: 0.00375
      currency: USD
    compliance:
      - GDPR
      - SOC2
    safety_features:
      - content_filtering
      - safety_ratings
      - harm_categories
    deployment:
      mode: API
      endpoint: https://generativelanguage.googleapis.com/v1beta/models
      authentication: API Key
    usage_limits:
      rate_limit_rpm: 2000
      concurrent_requests: 60
    fine_tuning:
      supported: true
      method: supervised fine-tuning
    notes: >-
      Gemini 1.5 Pro excels at multimodal understanding and can process large
      contexts including video and audio.
  - id: gpt-3.5-turbo
    name: GPT-3.5 Turbo
    provider: OpenAI
    version: 2023-11
    model_type: transformer
    description: Cost-effective for simple tasks
    badge: Budget
    badge_color: text-orange-600
    capabilities:
      - text_completion
      - basic_reasoning
      - summarization
      - code_generation
      - multilingual_support
    input:
      max_tokens: 16385
      token_encoding: cl100k_base
      formats_supported:
        - text
        - json
    output:
      response_format: text
      temperature: 0.7
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 300
      burst_latency_ms: 800
    cost_profile:
      prompt_token_cost_per_1k: 0.0015
      completion_token_cost_per_1k: 0.002
      currency: USD
    compliance:
      - GDPR
      - SOC2
      - ISO/IEC 27001
    safety_features:
      - content_filtering
      - PII_redaction
    deployment:
      mode: API
      endpoint: https://api.openai.com/v1/chat/completions
      authentication: Bearer Token
    usage_limits:
      rate_limit_rpm: 3500
      concurrent_requests: 100
    fine_tuning:
      supported: true
      method: instruction tuning
    notes: >-
      GPT-3.5 Turbo is optimized for speed and cost efficiency while maintaining
      good performance.
  - id: llama-3.1-405b
    name: Meta Llama 3.1 405B
    provider: Meta
    version: '3.1'
    model_type: transformer
    description: Meta's largest open source model with exceptional reasoning
    badge: Open Source
    badge_color: text-emerald-600
    capabilities:
      - text_completion
      - reasoning
      - code_generation
      - multilingual_support
      - function_calling
      - creative_writing
    input:
      max_tokens: 128000
      token_encoding: llama
      formats_supported:
        - text
        - json
    output:
      response_format: text
      temperature: 0.7
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 1200
      burst_latency_ms: 3000
    cost_profile:
      prompt_token_cost_per_1k: 0.00
      completion_token_cost_per_1k: 0.00
      currency: USD
    compliance:
      - Custom License
    safety_features:
      - configurable_safety
      - fine_tune_safety
    deployment:
      mode: Self-hosted
      endpoint: configurable
      authentication: Custom
    usage_limits:
      rate_limit_rpm: 1000
      concurrent_requests: 10
    fine_tuning:
      supported: true
      method: full_parameter_tuning
    notes: >-
      Llama 3.1 405B is Meta's flagship open source model, offering performance
      comparable to closed models with full customization capabilities.
  - id: llama-3.1-70b
    name: Meta Llama 3.1 70B
    provider: Meta
    version: '3.1'
    model_type: transformer
    description: High-performance open source model for production use
    badge: Open Source
    badge_color: text-emerald-600
    capabilities:
      - text_completion
      - reasoning
      - code_generation
      - multilingual_support
      - function_calling
    input:
      max_tokens: 128000
      token_encoding: llama
      formats_supported:
        - text
        - json
    output:
      response_format: text
      temperature: 0.7
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 800
      burst_latency_ms: 2000
    cost_profile:
      prompt_token_cost_per_1k: 0.00
      completion_token_cost_per_1k: 0.00
      currency: USD
    compliance:
      - Custom License
    safety_features:
      - configurable_safety
      - fine_tune_safety
    deployment:
      mode: Self-hosted
      endpoint: configurable
      authentication: Custom
    usage_limits:
      rate_limit_rpm: 2000
      concurrent_requests: 20
    fine_tuning:
      supported: true
      method: full_parameter_tuning
    notes: >-
      Llama 3.1 70B offers excellent performance for most tasks while being
      more resource-efficient than the 405B model.
  - id: mistral-7b-v0.3
    name: Mistral 7B v0.3
    provider: Mistral AI
    version: 'v0.3'
    model_type: transformer
    description: Efficient open source model with strong multilingual capabilities
    badge: Open Source
    badge_color: text-emerald-600
    capabilities:
      - text_completion
      - reasoning
      - code_generation
      - multilingual_support
    input:
      max_tokens: 32000
      token_encoding: mistral
      formats_supported:
        - text
        - json
    output:
      response_format: text
      temperature: 0.7
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 400
      burst_latency_ms: 1000
    cost_profile:
      prompt_token_cost_per_1k: 0.00
      completion_token_cost_per_1k: 0.00
      currency: USD
    compliance:
      - Apache 2.0
    safety_features:
      - configurable_safety
    deployment:
      mode: Self-hosted
      endpoint: configurable
      authentication: Custom
    usage_limits:
      rate_limit_rpm: 3000
      concurrent_requests: 30
    fine_tuning:
      supported: true
      method: lora_adapters
    notes: >-
      Mistral 7B is optimized for efficiency and multilingual performance,
      making it ideal for resource-constrained deployments.
  - id: qwen2.5-72b
    name: Qwen 2.5 72B
    provider: Alibaba Cloud
    version: '2.5'
    model_type: transformer
    description: Advanced multilingual model with strong reasoning capabilities
    badge: Open Source
    badge_color: text-emerald-600
    capabilities:
      - text_completion
      - reasoning
      - code_generation
      - multilingual_support
      - math_problem_solving
    input:
      max_tokens: 128000
      token_encoding: qwen
      formats_supported:
        - text
        - json
    output:
      response_format: text
      temperature: 0.7
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 900
      burst_latency_ms: 2200
    cost_profile:
      prompt_token_cost_per_1k: 0.00
      completion_token_cost_per_1k: 0.00
      currency: USD
    compliance:
      - Tongyi Qianwen License
    safety_features:
      - content_filtering
      - configurable_safety
    deployment:
      mode: Self-hosted
      endpoint: configurable
      authentication: Custom
    usage_limits:
      rate_limit_rpm: 1500
      concurrent_requests: 15
    fine_tuning:
      supported: true
      method: full_parameter_tuning
    notes: >-
      Qwen 2.5 72B excels in multilingual tasks and mathematical reasoning,
      with particular strength in Chinese language processing.
  - id: phi-3.5-mini
    name: Microsoft Phi-3.5 Mini
    provider: Microsoft
    version: '3.5'
    model_type: transformer
    description: Compact high-performance model for efficient deployment
    badge: Open Source
    badge_color: text-emerald-600
    capabilities:
      - text_completion
      - reasoning
      - code_generation
      - instruction_following
    input:
      max_tokens: 128000
      token_encoding: phi
      formats_supported:
        - text
        - json
    output:
      response_format: text
      temperature: 0.7
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 200
      burst_latency_ms: 500
    cost_profile:
      prompt_token_cost_per_1k: 0.00
      completion_token_cost_per_1k: 0.00
      currency: USD
    compliance:
      - MIT License
    safety_features:
      - built_in_safety
      - responsible_ai
    deployment:
      mode: Self-hosted
      endpoint: configurable
      authentication: Custom
    usage_limits:
      rate_limit_rpm: 5000
      concurrent_requests: 50
    fine_tuning:
      supported: true
      method: lora_adapters
    notes: >-
      Phi-3.5 Mini delivers impressive performance despite its compact size,
      making it perfect for edge deployment and resource-efficient applications.
  - id: codellama-34b
    name: Code Llama 34B
    provider: Meta
    version: '1.0'
    model_type: transformer
    description: Specialized open source model for code generation and completion
    badge: Code Specialist
    badge_color: text-cyan-600
    capabilities:
      - code_generation
      - code_completion
      - code_explanation
      - debugging_assistance
      - multiple_languages
    input:
      max_tokens: 100000
      token_encoding: llama
      formats_supported:
        - text
        - json
        - code
    output:
      response_format: text
      temperature: 0.1
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 1000
      burst_latency_ms: 2500
    cost_profile:
      prompt_token_cost_per_1k: 0.00
      completion_token_cost_per_1k: 0.00
      currency: USD
    compliance:
      - Custom License
    safety_features:
      - code_safety_filters
      - malicious_code_detection
    deployment:
      mode: Self-hosted
      endpoint: configurable
      authentication: Custom
    usage_limits:
      rate_limit_rpm: 1000
      concurrent_requests: 10
    fine_tuning:
      supported: true
      method: full_parameter_tuning
    notes: >-
      Code Llama 34B is specifically trained for programming tasks and supports
      over 20 programming languages with excellent code understanding.
  - id: deepseek-coder-33b
    name: DeepSeek Coder 33B
    provider: DeepSeek
    version: '1.3'
    model_type: transformer
    description: Advanced open source coding model with strong problem-solving
    badge: Code Specialist
    badge_color: text-cyan-600
    capabilities:
      - code_generation
      - code_completion
      - algorithm_design
      - code_optimization
      - technical_documentation
    input:
      max_tokens: 16000
      token_encoding: deepseek
      formats_supported:
        - text
        - json
        - code
    output:
      response_format: text
      temperature: 0.1
      top_p: 0.9
      max_tokens: 4096
    latency_profile:
      avg_latency_ms: 900
      burst_latency_ms: 2100
    cost_profile:
      prompt_token_cost_per_1k: 0.00
      completion_token_cost_per_1k: 0.00
      currency: USD
    compliance:
      - DeepSeek License
    safety_features:
      - code_safety_filters
      - secure_coding_practices
    deployment:
      mode: Self-hosted
      endpoint: configurable
      authentication: Custom
    usage_limits:
      rate_limit_rpm: 1200
      concurrent_requests: 12
    fine_tuning:
      supported: true
      method: full_parameter_tuning
    notes: >-
      DeepSeek Coder 33B specializes in complex coding tasks and algorithmic
      problem-solving with strong performance in competitive programming.
